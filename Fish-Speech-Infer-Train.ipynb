{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPirGf+HsaTSqNslXJENkSp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/None1024Outlook/64949499eebfcedcaa8236ed45b0c213/fish-speech-not-tested.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialization  \n",
        "You can access [this](http://blog.nonewiki.top) get some help"
      ],
      "metadata": {
        "id": "_Uv1gYprm_mn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Cloud Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "8oFL35jCmhnk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f90a85f5-74e7-4cf2-ac7d-ccbdbe9f9676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-KzKRG0l-8P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41e40aa6-91da-4560-8be6-00dc3ffbc636"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n",
            "Cloning into 'fish-speech'...\n",
            "remote: Enumerating objects: 5169, done.\u001b[K\n",
            "remote: Counting objects: 100% (267/267), done.\u001b[K\n",
            "remote: Compressing objects: 100% (156/156), done.\u001b[K\n",
            "remote: Total 5169 (delta 125), reused 182 (delta 69), pack-reused 4902 (from 1)\u001b[K\n",
            "Receiving objects: 100% (5169/5169), 18.50 MiB | 8.94 MiB/s, done.\n",
            "Resolving deltas: 100% (3348/3348), done.\n",
            "Updating files: 100% (156/156), done.\n",
            "/content/drive/MyDrive/fish-speech\n"
          ]
        }
      ],
      "source": [
        "# Clone Repo\n",
        "\n",
        "%cd /content/drive/MyDrive\n",
        "!git clone https://github.com/fishaudio/fish-speech.git\n",
        "%cd fish-speech\n",
        "!git checkout tags/v1.4.3 # Because the current 1.4 version is more stable, we are using 1.4.3 here. You can replace here"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/fish-speech\n",
        "\n",
        "# Install\n",
        "\n",
        "!sudo apt install libasound-dev portaudio19-dev libportaudio2 libportaudiocpp0\n",
        "!pip install pyaudio\n",
        "!pip install huggingface_hub\n",
        "!pip install triton\n",
        "!pip install .\n",
        "# !huggingface-cli login # If you want to use version 1.5 of the model, please uncomment it\n",
        "!huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4 #  You can replace here"
      ],
      "metadata": {
        "id": "7ThNEL9YmrcG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db5d874e-9cbf-455e-8764-595f13929887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Value\n",
        "checkpoint = \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\" #@param {type: \"string\"}\n",
        "base_weight = \"checkpoints/fish-speech-1.4\" #@param {type: \"string\"}"
      ],
      "metadata": {
        "id": "gwxnpBd9qTHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-tuning"
      ],
      "metadata": {
        "id": "52fYyEqom9xg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/fish-speech\n",
        "\n",
        "# Batch extraction of semantic tokens\n",
        "config_name = \"firefly_gan_vq\" #@param {type: \"string\"}\n",
        "!python tools/vqgan/extract_vq.py data --num-workers 1 --batch-size 16 --config-name {config_name} --checkpoint-path {checkpoint}\n",
        "\n",
        "# Pack the dataset into protobuf\n",
        "!python tools/llama/build_dataset.py --input \"data\" --output \"data/protos\" --text-extension .lab --num-workers 16"
      ],
      "metadata": {
        "id": "zQ55Y_-snFHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/fish-speech\n",
        "\n",
        "# Fine-tuning with LoRA\n",
        "config_name = \"text2semantic_finetune\" #@param {type: \"string\"}\n",
        "projext = \"Speaker1\" #@param {type: \"string\"}\n",
        "lora_config_name = \"r_8_alpha_16\" #@param {type: \"string\"}\n",
        "!python fish_speech/train.py --config-name {config_name} project={projext} +lora@model.model.lora_config={lora_config_name}"
      ],
      "metadata": {
        "id": "nVq_M0ltncrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/fish-speech\n",
        "\n",
        "# Convert the LoRA weights to regular weights\n",
        "lora_weight = \"results/Speaker1/checkpoints/step_000000010.ckpt\" #@param {type: \"string\"}\n",
        "output_path = \"checkpoints/fish-speech-1.4-Speaker1-lora/\" #@param {type: \"string\"}\n",
        "!python tools/llama/merge_lora.py --lora-config {lora_config_name} --base-weight {base_weight} --lora-weight {lora_weight} --output {output}"
      ],
      "metadata": {
        "id": "8HffCAmwnlYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference"
      ],
      "metadata": {
        "id": "Bnh3ALQGnwmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/fish-speech\n",
        "\n",
        "# Generate prompt from voice\n",
        "input_wav = \"/content/drive/fish-speech/speaker1.wav\" #@param {type: \"string\"}\n",
        "!python tools/vqgan/inference.py -i {input_wav} --checkpoint-path {checkpoint}"
      ],
      "metadata": {
        "id": "EI5WirwOn37O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/fish-speech\n",
        "\n",
        "# Generate semantic tokens from text\n",
        "output_wav_text = \"The text you want to convert\" #@param {type: \"string\"}\n",
        "input_wav_text = \"Your reference text\" #@param {type: \"string\"}\n",
        "npy_path = \"/content/drive/fish-speech/fake.npy\" #@param {type: \"string\"}\n",
        "!python tools/llama/generate.py --text {output_wav_text} --prompt-text {input_wav_text} --prompt-tokens {npy_path} --checkpoint-path {base_weight} --num-samples 2\n",
        "\n",
        "# Generate semantic tokens from text\n",
        "input_npy = \"/content/drive/fish-speech/codes_0.npy\" #@param {type: \"string\"}\n",
        "!python tools/vqgan/inference.py -i {input_npy} --checkpoint-path {checkpoint}"
      ],
      "metadata": {
        "id": "tGwUyHMooM5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Webui"
      ],
      "metadata": {
        "id": "rvG_kF_KrAMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/fish-speech\n",
        "\n",
        "# Download Cloudflared\n",
        "!wget https://github.com/cloudflare/cloudflared/releases/download/2024.11.1/cloudflared-linux-386 -O cloudflared\n",
        "!chmod +x cloudflared\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU_YVo7mqjhG",
        "outputId": "2c28c96e-b764-4eec-911b-26691a5dfd77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-05 16:39:26--  https://github.com/cloudflare/cloudflared/releases/download/2024.11.1/cloudflared-linux-386\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/78e7b426-3baf-4d66-868a-116c8d043946?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241205%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241205T163926Z&X-Amz-Expires=300&X-Amz-Signature=a7e4fd0c1208a2a9f683ecdbb689808f58d83b2ff9526fda8642531c93f0ab4f&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-386&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-12-05 16:39:26--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/78e7b426-3baf-4d66-868a-116c8d043946?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241205%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241205T163926Z&X-Amz-Expires=300&X-Amz-Signature=a7e4fd0c1208a2a9f683ecdbb689808f58d83b2ff9526fda8642531c93f0ab4f&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-386&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34556105 (33M) [application/octet-stream]\n",
            "Saving to: ‘cloudflared’\n",
            "\n",
            "cloudflared         100%[===================>]  32.96M  60.3MB/s    in 0.5s    \n",
            "\n",
            "2024-12-05 16:39:28 (60.3 MB/s) - ‘cloudflared’ saved [34556105/34556105]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/fish-speech\n",
        "\n",
        "llama_checkpoint_path = \"checkpoints/fish-speech-1.4\" #@param {type: \"string\"}\n",
        "docoder_checkpoint_path = \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\" #@param {type: \"string\"}\n",
        "docoder_config_name = \"firefly_gan_vq\" #@param {type: \"string\"}\n",
        "\n",
        "# You need to add share=True to the code that starts the webui in tools/webui.py\n",
        "!./cloudflared tunnel --url localhost:7860 | python -m tools.webui --llama-checkpoint-path {llama_checkpoint_path} --decoder-checkpoint-path {docoder_checkpoint_path} --decoder-config-name {docoder_config_name}"
      ],
      "metadata": {
        "id": "zWsIu3Pqq_JV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50e93000-c672-4291-998f-ab504bc6a7f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2024-12-05T16:42:32Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2024-12-05T16:42:32Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\u001b[90m2024-12-05T16:42:38Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2024-12-05T16:42:38Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2024-12-05T16:42:38Z\u001b[0m \u001b[32mINF\u001b[0m |  https://upon-supporters-lanka-lies.trycloudflare.com                                      |\n",
            "\u001b[90m2024-12-05T16:42:38Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2024-12-05T16:42:38Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2024-12-05T16:42:38Z\u001b[0m \u001b[32mINF\u001b[0m Version 2024.11.1 (Checksum 5761d65fb6fb23ea8e401abe3e471e316ee275f4b054f3ff55fd26a84228d096)\n",
            "\u001b[90m2024-12-05T16:42:38Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.22.5, GoArch: 386\n",
            "\u001b[90m2024-12-05T16:42:38Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 protocol:quic url:localhost:7860]\n",
            "\u001b[90m2024-12-05T16:42:38Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: c32fd687-558a-4e9b-afb1-de88c5d6c4b7\n",
            "\u001b[90m2024-12-05T16:42:38Z\u001b[0m \u001b[32mINF\u001b[0m Autoupdate frequency is set \u001b[36mautoupdateFreq=\u001b[0m86400000\n",
            "\u001b[90m2024-12-05T16:42:38Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2024-12-05T16:42:38Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2024-12-05T16:42:38Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2024-12-05T16:42:38Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:37969/metrics\n",
            "2024/12/05 16:42:38 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2024-12-05T16:42:39Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0mc1e89764-7b70-4835-ba8f-e76ca3e7a438 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.167 \u001b[36mlocation=\u001b[0msin08 \u001b[36mprotocol=\u001b[0mquic\n",
            "\u001b[32m2024-12-05 16:42:47.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m532\u001b[0m - \u001b[1mLoading Llama model...\u001b[0m\n",
            "\u001b[32m2024-12-05 16:43:01.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m682\u001b[0m - \u001b[1mRestored model from checkpoint\u001b[0m\n",
            "\u001b[32m2024-12-05 16:43:01.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m688\u001b[0m - \u001b[1mUsing DualARTransformer\u001b[0m\n",
            "\u001b[32m2024-12-05 16:43:01.630\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m539\u001b[0m - \u001b[1mLlama model loaded, loading VQ-GAN model...\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/vector_quantize_pytorch/vector_quantize_pytorch.py:445: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @autocast(enabled = False)\n",
            "/usr/local/lib/python3.10/dist-packages/vector_quantize_pytorch/vector_quantize_pytorch.py:630: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @autocast(enabled = False)\n",
            "/usr/local/lib/python3.10/dist-packages/vector_quantize_pytorch/finite_scalar_quantization.py:147: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @autocast(enabled = False)\n",
            "/usr/local/lib/python3.10/dist-packages/vector_quantize_pytorch/lookup_free_quantization.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @autocast(enabled = False)\n",
            "\u001b[32m2024-12-05 16:43:03.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.vqgan.inference\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mLoaded model: <All keys matched successfully>\u001b[0m\n",
            "\u001b[32m2024-12-05 16:43:03.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m547\u001b[0m - \u001b[1mDecoder model loaded, warming up...\u001b[0m\n",
            "\u001b[32m2024-12-05 16:43:03.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mEncoded text: Hello world.\u001b[0m\n",
            "\u001b[32m2024-12-05 16:43:03.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m807\u001b[0m - \u001b[1mGenerating sentence 1/1 of sample 1/1\u001b[0m\n",
            "  0% 0/8168 [00:00<?, ?it/s]/usr/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
            "  self.gen = func(*args, **kwds)\n",
            "  0% 14/8168 [00:01<12:26, 10.93it/s]\n",
            "\u001b[32m2024-12-05 16:43:06.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m861\u001b[0m - \u001b[1mGenerated 16 tokens in 2.78 seconds, 5.75 tokens/sec\u001b[0m\n",
            "\u001b[32m2024-12-05 16:43:06.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m864\u001b[0m - \u001b[1mBandwidth achieved: 3.67 GB/s\u001b[0m\n",
            "\u001b[32m2024-12-05 16:43:06.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.llama.generate\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m869\u001b[0m - \u001b[1mGPU Memory used: 1.84 GB\u001b[0m\n",
            "\u001b[32m2024-12-05 16:43:06.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtools.api\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mVQ features: torch.Size([8, 15])\u001b[0m\n",
            "\u001b[32m2024-12-05 16:43:06.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m567\u001b[0m - \u001b[1mWarming up done, launching the web UI...\u001b[0m\n",
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n",
            "\u001b[90m2024-12-05T16:44:05Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 89 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:7860\n",
            "\u001b[90m2024-12-05T16:44:05Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 89 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://upon-supporters-lanka-lies.trycloudflare.com/assets/index-9GPo9fAK.js \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.167 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2024-12-05T16:44:05Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 97 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:7860\n",
            "\u001b[90m2024-12-05T16:44:05Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 97 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://upon-supporters-lanka-lies.trycloudflare.com/assets/index-9GPo9fAK.js \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.167 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2024-12-05T16:44:31Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 505 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:7860\n",
            "\u001b[90m2024-12-05T16:44:31Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 505 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://upon-supporters-lanka-lies.trycloudflare.com/assets/IconButton-DtUbToT-.js \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.167 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2024-12-05T16:44:31Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 493 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:7860\n",
            "\u001b[90m2024-12-05T16:44:31Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 493 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://upon-supporters-lanka-lies.trycloudflare.com/assets/index-DFGa5OkC.js \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.167 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2024-12-05T16:44:31Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 513 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:7860\n",
            "\u001b[90m2024-12-05T16:44:31Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 513 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://upon-supporters-lanka-lies.trycloudflare.com/assets/MarkdownCode-CRbfKeek.css \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.167 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2024-12-05T16:44:31Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 509 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:7860\n",
            "\u001b[90m2024-12-05T16:44:31Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 509 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://upon-supporters-lanka-lies.trycloudflare.com/assets/IconButtonWrapper.svelte_svelte_type_style_lang-DAP8_Zsr.js \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.167 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2024-12-05T16:44:31Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 497 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:7860\n",
            "\u001b[90m2024-12-05T16:44:31Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 497 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://upon-supporters-lanka-lies.trycloudflare.com/assets/IconButtonWrapper-6oLg_adW.css \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.167 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2024-12-05T16:44:31Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 517 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:7860\n",
            "\u001b[90m2024-12-05T16:44:31Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 517 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://upon-supporters-lanka-lies.trycloudflare.com/assets/StreamingBar.svelte_svelte_type_style_lang-CxOfZBE-.js \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.167 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2024-12-05T16:44:31Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 537 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:7860\n",
            "\u001b[90m2024-12-05T16:44:31Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 537 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://upon-supporters-lanka-lies.trycloudflare.com/assets/prism-python-DvZkGt9M.js \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.167 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2024-12-05T16:44:31Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 489 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:7860\n",
            "\u001b[90m2024-12-05T16:44:31Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 489 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://upon-supporters-lanka-lies.trycloudflare.com/assets/StreamingBar-DPKKRe-n.css \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.167 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2024-12-05T16:44:31Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 525 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:7860\n",
            "\u001b[90m2024-12-05T16:44:31Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 525 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://upon-supporters-lanka-lies.trycloudflare.com/assets/MarkdownCode.svelte_svelte_type_style_lang-A3JQJUff.js \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.167 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2024-12-05T16:44:31Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m  \u001b[31merror=\u001b[0m\u001b[31m\"stream 541 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m1 \u001b[36mingressRule=\u001b[0m0 \u001b[36moriginService=\u001b[0mhttp://localhost:7860\n",
            "\u001b[90m2024-12-05T16:44:31Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Request failed \u001b[31merror=\u001b[0m\u001b[31m\"stream 541 canceled by remote with error code 0\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mdest=\u001b[0mhttps://upon-supporters-lanka-lies.trycloudflare.com/assets/svelte/svelte.js \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.167 \u001b[36mtype=\u001b[0mhttp\n",
            "\u001b[90m2024-12-05T16:45:03Z\u001b[0m \u001b[32mINF\u001b[0m Initiating graceful shutdown due to signal interrupt ...\n",
            "Keyboard interruption in main thread... closing server.\n",
            "\u001b[90m2024-12-05T16:45:04Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Failed to serve tunnel connection \u001b[31merror=\u001b[0m\u001b[31m\"context canceled\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.167\n",
            "\u001b[90m2024-12-05T16:45:04Z\u001b[0m \u001b[32mINF\u001b[0m Retrying connection in up to 1s \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.167\n",
            "\u001b[90m2024-12-05T16:45:04Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m no more connections active and exiting\n",
            "\u001b[90m2024-12-05T16:45:04Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel server stopped\n",
            "\u001b[90m2024-12-05T16:45:04Z\u001b[0m \u001b[32mINF\u001b[0m Metrics server stopped\n"
          ]
        }
      ]
    }
  ]
}
