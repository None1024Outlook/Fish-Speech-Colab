{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "to colab",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/drive/1trBvrdgyI-Ntd45ZnlT5lhGsI_HnKjC1?usp=sharing\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialization  \n",
        "You can access [this](http://blog.nonewiki.top) get some help"
      ],
      "metadata": {
        "id": "_Uv1gYprm_mn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Are you using Colab\n",
        "useColab = True #@param {type:\"boolean\"}\n",
        "if useColab:\n",
        "  # Mount Google Cloud Drive\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  %cd /content/drive/MyDrive\n",
        "else:\n",
        "  %cd ."
      ],
      "metadata": {
        "id": "8oFL35jCmhnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-KzKRG0l-8P"
      },
      "outputs": [],
      "source": [
        "# Clone Repo\n",
        "import os\n",
        "if not os.path.exists(\"fish-speech\"):\n",
        "  !git clone https://github.com/fishaudio/fish-speech.git\n",
        "  !git checkout tags/v1.4.3 # Because the current 1.4 version is more stable, we are using 1.4.3 here. You can replace here\n",
        "else:\n",
        "  print(\"The Fish Speech project is already in the directory.\")\n",
        "# Enter the project directory\n",
        "%cd fish-speech"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Packages\n",
        "!sudo apt install libasound-dev portaudio19-dev libportaudio2 libportaudiocpp0\n",
        "!pip install pyaudio\n",
        "!pip install huggingface_hub\n",
        "!pip install triton\n",
        "!pip install .\n",
        "# !huggingface-cli login # If you want to use version 1.5 of the model, please uncomment it\n",
        "model_id = \"fishaudio/fish-speech-1.4\" #@param {type:\"string\"}\n",
        "download_dir = \"checkpoints/fish-speech-1.4\" #@param {type:\"string\"}\n",
        "!huggingface-cli download {model_id} --local-dir {download_dir} #  You can replace here"
      ],
      "metadata": {
        "id": "7ThNEL9YmrcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the necessary variables."
      ],
      "metadata": {
        "id": "YmlIfbpj8FNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Value\n",
        "vqgan_model = \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\" #@param {type: \"string\"}\n",
        "vqgan_config_name = \"firefly_gan_vq\" #@param {type: \"string\"}\n",
        "llama_model = \"checkpoints/fish-speech-1.4\" #@param {type: \"string\"}"
      ],
      "metadata": {
        "id": "gwxnpBd9qTHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-tuning"
      ],
      "metadata": {
        "id": "52fYyEqom9xg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Datasets\n",
        "\n",
        "# Batch extraction of semantic tokens\n",
        "!python tools/vqgan/extract_vq.py data --num-workers 1 --batch-size 16 --config-name {vqgan_config_name} --checkpoint-path {vqgan_model}\n",
        "\n",
        "# Pack the dataset into protobuf\n",
        "input_dir = \"data\" #@param {type: \"string\"}\n",
        "output_dir = \"data/protos\" #@param {type: \"string\"}\n",
        "!python tools/llama/build_dataset.py --input {input_dir} --output {output_dir} --text-extension .lab --num-workers 16"
      ],
      "metadata": {
        "id": "zQ55Y_-snFHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the training configuration file\n",
        "\n",
        "import yaml\n",
        "project = \"Speaker1\" #@param {type: \"string\"}\n",
        "train_config_name = \"text2semantic_finetune\" #@param {type: \"string\"}\n",
        "lora_config_name = \"r_8_alpha_16\" #@param {type: \"string\"}\n",
        "train_config_path = f\"fish_speech/configs/{train_config_name}.yaml\"\n",
        "if not os.path.exists(train_config_path):\n",
        "  print(f\"The file {train_config_path} does not exist.\")\n",
        "  raise FileNotFoundError(train_config_path)\n",
        "with open(train_config_path, \"r\", encoding=\"utf-8\") as file:\n",
        "  data = yaml.load(file, Loader=yaml.FullLoader)\n",
        "pretrained_ckpt_path = \"checkpoints/fish-speech-1.4\" #@param {type: \"string\"}\n",
        "protos_dir = \"data/protos\" #@param {type: \"string\"}\n",
        "max_steps = 1000 #@param {type: \"integer\"}\n",
        "num_workers = 1 #@param {type: \"integer\"}\n",
        "batch_size = 1 #@param {type: \"integer\"}\n",
        "data[\"project\"] = project\n",
        "data[\"pretrained_ckpt_path\"] = pretrained_ckpt_path\n",
        "data[\"trainer\"][\"max_steps\"] = max_steps\n",
        "data[\"data\"][\"num_workers\"] = num_workers\n",
        "data[\"data\"][\"batch_size\"] = batch_size\n",
        "data[\"train_dataset\"][\"proto_files\"] = [protos_dir]\n",
        "with open(train_config_path, \"w\", encoding=\"utf-8\") as file:\n",
        "  yaml.dump(data, file, allow_unicode=True)"
      ],
      "metadata": {
        "id": "iJ5NPAV1_xRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tuning with LoRA\n",
        "!python fish_speech/train.py --config-name {train_config_name}"
      ],
      "metadata": {
        "id": "nVq_M0ltncrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the LoRA weights to regular weights\n",
        "lora_weight = \"results/Speaker1/checkpoints/step_000000010.ckpt\" #@param {type: \"string\"}\n",
        "output_path = \"checkpoints/fish-speech-1.4-Speaker1-lora/\" #@param {type: \"string\"}\n",
        "!python tools/llama/merge_lora.py --lora-config {lora_config_name} --base-weight {llama_model} --lora-weight {lora_weight} --output {output}"
      ],
      "metadata": {
        "id": "8HffCAmwnlYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference"
      ],
      "metadata": {
        "id": "Bnh3ALQGnwmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate prompt from voice\n",
        "prompt_wav = \"Speaker1.wav\" #@param {type: \"string\"}\n",
        "output_npy = \"fake.npy\" #@param {type: \"string\"}\n",
        "!python tools/vqgan/inference.py -i {prompt_wav} -o {output_npy} --checkpoint-path {vqgan_model} --device {device}"
      ],
      "metadata": {
        "id": "EI5WirwOn37O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate semantic tokens from text\n",
        "output_wav_text = \"Hello everyone! Welcome to Apple Park\" #@param {type: \"string\"}\n",
        "output_wav = \"fake_Speaker1.wav\" #@param {type: \"string\"}\n",
        "prompt_wav_text = \"Prompt wav text\" #@param {type: \"string\"}\n",
        "prompt_npy = \"fake.npy\" #@param {type: \"string\"}\n",
        "!python tools/llama/generate.py --text {output_wav_text} --prompt-text {prompt_wav_text} --prompt-tokens {prompt_npy} --checkpoint-path {llama_model} --num-samples 2\n",
        "\n",
        "# Generate semantic tokens from text\n",
        "input_npy = \"codes_0.npy\" #@param {type: \"string\"}\n",
        "!python tools/vqgan/inference.py -i {input_npy} -o {output_wav} --device {device} --checkpoint-path {vqgan_model}\n",
        "\n",
        "# Play\n",
        "from IPython.display import Audio, display\n",
        "display(Audio(output_wav, autoplay=False))"
      ],
      "metadata": {
        "id": "tGwUyHMooM5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Webui"
      ],
      "metadata": {
        "id": "rvG_kF_KrAMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Cloudflared\n",
        "!wget https://github.com/cloudflare/cloudflared/releases/download/2024.11.1/cloudflared-linux-386 -O cloudflared\n",
        "!chmod +x cloudflared"
      ],
      "metadata": {
        "id": "dU_YVo7mqjhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run webui\n",
        "!./cloudflared tunnel --url 127.0.0.1:7860 | python -m tools.webui --llama-checkpoint-path {llama_model} --decoder-checkpoint-path {vqgan_config_name} --decoder-config-name {vqgan_model}"
      ],
      "metadata": {
        "id": "zWsIu3Pqq_JV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}