{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/drive/1trBvrdgyI-Ntd45ZnlT5lhGsI_HnKjC1?usp=sharing\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>"
      ],
      "metadata": {
        "id": "t_G3YhdvX1qS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialization  \n",
        "You can access [this](http://blog.nonewiki.top) get some help"
      ],
      "metadata": {
        "id": "_Uv1gYprm_mn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Are you using Colab\n",
        "useColab = True #@param {type:\"boolean\"}\n",
        "if useColab:\n",
        "  # Mount Google Cloud Drive\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  %cd /content/drive/MyDrive\n",
        "else:\n",
        "  %cd ."
      ],
      "metadata": {
        "id": "8oFL35jCmhnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1-KzKRG0l-8P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4d4c3d6-4755-424f-83cd-1e442147423f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Fish Speech project is already in the directory.\n",
            "/content/drive/MyDrive/fish-speech\n"
          ]
        }
      ],
      "source": [
        "# Clone Repo\n",
        "import os\n",
        "if not os.path.exists(\"fish-speech\"):\n",
        "  !git clone https://github.com/fishaudio/fish-speech.git\n",
        "  !git checkout tags/v1.4.3 # Because the current 1.4 version is more stable, we are using 1.4.3 here. You can replace here\n",
        "else:\n",
        "  print(\"The Fish Speech project is already in the directory.\")\n",
        "# Enter the project directory\n",
        "%cd fish-speech"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Packages\n",
        "!sudo apt install libasound-dev portaudio19-dev libportaudio2 libportaudiocpp0\n",
        "!pip install pyaudio\n",
        "!pip install huggingface_hub\n",
        "!pip install triton\n",
        "!pip install .\n",
        "# !huggingface-cli login # If you want to use version 1.5 of the model, please uncomment it\n",
        "model_id = \"fishaudio/fish-speech-1.4\" #@param {type:\"string\"}\n",
        "download_dir = \"checkpoints/fish-speech-1.4\" #@param {type:\"string\"}\n",
        "!huggingface-cli download {model_id} --local-dir {download_dir} #  You can replace here"
      ],
      "metadata": {
        "id": "7ThNEL9YmrcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the necessary variables."
      ],
      "metadata": {
        "id": "YmlIfbpj8FNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Value\n",
        "# If you are using a version of the repository other than 1.4, please change the values here\n",
        "vqgan_model = \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\" #@param {type: \"string\"}\n",
        "vqgan_config_name = \"firefly_gan_vq\" #@param {type: \"string\"}\n",
        "llama_model = \"checkpoints/fish-speech-1.4\" #@param {type: \"string\"}\n",
        "device = \"cuda\" #@param [\"cuda\", \"cpu\"]\n",
        "useCompile = True #@param {type: \"boolean\"}"
      ],
      "metadata": {
        "id": "gwxnpBd9qTHO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-tuning"
      ],
      "metadata": {
        "id": "52fYyEqom9xg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Datasets\n",
        "\n",
        "# Batch extraction of semantic tokens\n",
        "!python tools/vqgan/extract_vq.py data --num-workers 1 --batch-size 16 --config-name {vqgan_config_name} --checkpoint-path {vqgan_model}\n",
        "\n",
        "# Pack the dataset into protobuf\n",
        "input_dir = \"data\" #@param {type: \"string\"}\n",
        "output_dir = \"data/protos\" #@param {type: \"string\"}\n",
        "!python tools/llama/build_dataset.py --input {input_dir} --output {output_dir} --text-extension .lab --num-workers 16"
      ],
      "metadata": {
        "id": "zQ55Y_-snFHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up training configuration file\n",
        "\n",
        "import yaml\n",
        "project = \"Speaker1\" #@param {type: \"string\"}\n",
        "train_config_name = \"text2semantic_finetune\" #@param {type: \"string\"}\n",
        "lora_config_name = \"r_8_alpha_16\" #@param {type: \"string\"}\n",
        "train_config_path = f\"fish_speech/configs/{train_config_name}.yaml\"\n",
        "if not os.path.exists(train_config_path):\n",
        "  print(f\"The file {train_config_path} does not exist.\")\n",
        "  raise FileNotFoundError(train_config_path)\n",
        "with open(train_config_path, \"r\", encoding=\"utf-8\") as file:\n",
        "  data = yaml.load(file, Loader=yaml.FullLoader)\n",
        "pretrained_ckpt_path = \"checkpoints/fish-speech-1.4\" #@param {type: \"string\"}\n",
        "protos_dir = \"data/protos\" #@param {type: \"string\"}\n",
        "max_steps = 1000 #@param {type: \"integer\"}\n",
        "num_workers = 1 #@param {type: \"integer\"}\n",
        "batch_size = 1 #@param {type: \"integer\"}\n",
        "data[\"project\"] = project\n",
        "data[\"pretrained_ckpt_path\"] = pretrained_ckpt_path\n",
        "data[\"trainer\"][\"max_steps\"] = max_steps\n",
        "data[\"data\"][\"num_workers\"] = num_workers\n",
        "data[\"data\"][\"batch_size\"] = batch_size\n",
        "data[\"model\"][\"model\"][\"lora_config\"] = lora_config_name\n",
        "data[\"train_dataset\"][\"proto_files\"] = [protos_dir]\n",
        "data[\"val_dataset\"][\"proto_files\"] = [protos_dir]\n",
        "with open(train_config_path, \"w\", encoding=\"utf-8\") as file:\n",
        "  yaml.dump(data, file, allow_unicode=True)"
      ],
      "metadata": {
        "id": "iJ5NPAV1_xRP"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training configuration file\n",
        "import yaml\n",
        "train_config_name = \"text2semantic_finetune\" #@param {type: \"string\"}\n",
        "train_config_path = f\"fish_speech/configs/{train_config_name}.yaml\"\n",
        "if not os.path.exists(train_config_path):\n",
        "  print(f\"The file {train_config_path} does not exist.\")\n",
        "  raise FileNotFoundError(train_config_path)\n",
        "with open(train_config_path, \"r\", encoding=\"utf-8\") as file:\n",
        "  data = yaml.load(file, Loader=yaml.FullLoader)\n",
        "project = data[\"project\"]\n",
        "pretrained_ckpt_path = data[\"pretrained_ckpt_path\"]\n",
        "lora_config_name = data[\"model\"][\"model\"][\"lora_config\"]\n",
        "print(f\"Project: {project}\")\n",
        "print(f\"Pretrained ckpt path: {pretrained_ckpt_path}\")"
      ],
      "metadata": {
        "id": "T9JgesfFTLVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Please execute \"# Load training configuration file\"\n",
        "# Fine-tuning with LoRA\n",
        "!python fish_speech/train.py --config-name {train_config_name}"
      ],
      "metadata": {
        "id": "nVq_M0ltncrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Please execute \"# Load training configuration file\"\n",
        "# Convert the LoRA weights to regular weights\n",
        "autoLoRA = False #@param {type: \"boolean\"}\n",
        "if autoLoRA:\n",
        "  import re\n",
        "  lora_dir_path = f\"results/{project}/checkpoints\"\n",
        "  files = [f for f in os.listdir(lora_dir_path) if re.match(r\"step_\\d+\\.ckpt\", f)]\n",
        "  lora_weight = f\"{lora_dir_path}/{max(files, key=lambda f: int(re.search(r'\\d+', f).group()))}\"\n",
        "else:\n",
        "  lora_weight = \"results/Speaker1/checkpoints/step_000000010.ckpt\" #@param {type: \"string\"}\n",
        "output_path = \"checkpoints/fish-speech-1.4-Speaker1-lora/\" #@param {type: \"string\"}\n",
        "!python tools/llama/merge_lora.py --lora-config {lora_config_name} --base-weight {pretrained_ckpt_path} --lora-weight {lora_weight} --output {output}"
      ],
      "metadata": {
        "id": "8HffCAmwnlYn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6805b532-160d-43e1-aacb-48d0e0ffe9ab"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/fish-speech\n",
            "The file with the largest number is: step_00123.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Please execute \"# Load training configuration file\"\n",
        "# Continue training\n",
        "autoLatestLoRA = False #@param {type: \"boolean\"}\n",
        "if autoLatestLoRA:\n",
        "  import re\n",
        "  lora_dir_path = f\"results/{project}/checkpoints\"\n",
        "  files = [f for f in os.listdir(lora_dir_path) if re.match(r\"step_\\d+\\.ckpt\", f)]\n",
        "  latest_lora_weight = f\"{lora_dir_path}/{max(files, key=lambda f: int(re.search(r'\\d+', f).group()))}\"\n",
        "else:\n",
        "  latest_lora_weight = \"results/Speaker1/checkpoints/step_000000010.ckpt\" #@param {type: \"string\"}\n",
        "import time\n",
        "output_path = f\"checkpoints/{time.time()}/\".replace(\".\", \"_\")\n",
        "!python tools/llama/merge_lora.py --lora-config {lora_config_name} --base-weight {pretrained_ckpt_path} --lora-weight {latest_lora_weight} --output {output}\n",
        "if not os.path.exists(train_config_path):\n",
        "  print(f\"The file {train_config_path} does not exist.\")\n",
        "  raise FileNotFoundError(train_config_path)\n",
        "with open(train_config_path, \"r\", encoding=\"utf-8\") as file:\n",
        "  data = yaml.load(file, Loader=yaml.FullLoader)\n",
        "pretrained_ckpt_path = output_path[:-1]\n",
        "data[\"pretrained_ckpt_path\"] = pretrained_ckpt_path\n",
        "with open(train_config_path, \"w\", encoding=\"utf-8\") as file:\n",
        "  yaml.dump(data, file, allow_unicode=True)\n",
        "input(\"Please delete all the .ckpt files in the latest_lora_weight folder\")\n",
        "!python fish_speech/train.py --config-name {train_config_name}"
      ],
      "metadata": {
        "id": "rXcJ6QF4SIAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference"
      ],
      "metadata": {
        "id": "Bnh3ALQGnwmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate prompt from voice\n",
        "# If you plan to let the model randomly choose a voice timbre, you can skip this step\n",
        "prompt_wav = \"Speaker1.wav\" #@param {type: \"string\"}\n",
        "output_npy = \"fake.npy\" #@param {type: \"string\"}\n",
        "!python tools/vqgan/inference.py -i {prompt_wav} -o {output_npy} --checkpoint-path {vqgan_model} --device {device"
      ],
      "metadata": {
        "id": "EI5WirwOn37O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate semantic tokens from text\n",
        "output_wav_text = \"Hello everyone! Welcome to Apple Park\" #@param {type: \"string\"}\n",
        "output_wav = \"fake_Speaker1.wav\" #@param {type: \"string\"}\n",
        "prompt_wav_text = \"Prompt wav text\" #@param {type: \"string\"}\n",
        "prompt_npy = \"fake.npy\" #@param {type: \"string\"}\n",
        "if useCompile:\n",
        "  !python tools/llama/generate.py --text {output_wav_text} --prompt-text {prompt_wav_text} --prompt-tokens {prompt_npy} --checkpoint-path {llama_model} --num-samples 2 --compile --device {device}\n",
        "else:\n",
        "  !python tools/llama/generate.py --text {output_wav_text} --prompt-text {prompt_wav_text} --prompt-tokens {prompt_npy} --checkpoint-path {llama_model} --num-samples 2 --device {device}\n",
        "\n",
        "# Generate semantic tokens from text\n",
        "input_npy = \"codes_0.npy\" #@param {type: \"string\"}\n",
        "!python tools/vqgan/inference.py -i {input_npy} -o {output_wav} --device {device} --checkpoint-path {vqgan_model}\n",
        "\n",
        "# Play\n",
        "from IPython.display import Audio, display\n",
        "display(Audio(output_wav, autoplay=False))"
      ],
      "metadata": {
        "id": "tGwUyHMooM5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Webui"
      ],
      "metadata": {
        "id": "rvG_kF_KrAMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Cloudflared\n",
        "!wget https://github.com/cloudflare/cloudflared/releases/download/2024.11.1/cloudflared-linux-386 -O cloudflared\n",
        "!chmod +x cloudflared"
      ],
      "metadata": {
        "id": "dU_YVo7mqjhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run webui\n",
        "if useCompile:\n",
        "  !./cloudflared tunnel --url 127.0.0.1:7860 | python -m tools.webui --llama-checkpoint-path {llama_model} --decoder-checkpoint-path {vqgan_model} --decoder-config-name {vqgan_config_name} --compile --device {device}\n",
        "else:\n",
        "  !./cloudflared tunnel --url 127.0.0.1:7860 | python -m tools.webui --llama-checkpoint-path {llama_model} --decoder-checkpoint-path {vqgan_model} --decoder-config-name {vqgan_config_name} --device {device}"
      ],
      "metadata": {
        "id": "zWsIu3Pqq_JV"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}